from nltk.tokenize import word_tokenize

example_sentence = 'This is a sentence. Here is another one.'

print(word_tokenize(example_sentence))